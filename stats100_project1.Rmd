---
title: "Stats 100: Homework 3"
author: "Niall Kehoe"
date: "05/11/2023"
header-includes:
   - \usepackage{bbm, amsmath,amsfonts,amsthm,amssymb,mathrsfs,amsxtra,amscd,latexsym, xcolor, graphicx, fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
output: pdf_document
---

\newcommand{\Var}{\mathrm{Var}}

```{r}
#in order to run this code, you will need to install these packages. You can do so by going to the install button, or by going to the console and typing, for example, install.packages("knitr")
suppressPackageStartupMessages(library(knitr)) #makes pdfs
suppressPackageStartupMessages(library(latex2exp))
suppressPackageStartupMessages(library(ggplot2)) #makes nice plots
suppressPackageStartupMessages(library(tidyverse))
#good library for data manipulation, includes dplyr and ggplot
# you can read more about the tidyverse at: https://r4ds.had.co.nz/
# you'll need this library for regularization if you use it

#install.packages('glmnet', dependencies=TRUE, type="binary")
#install.packages('predtools', dependencies=TRUE, type="binary")
#install.packages('psych', dependencies=TRUE, type="binary")

suppressPackageStartupMessages(library(glmnet))
suppressPackageStartupMessages(library(predtools))
suppressPackageStartupMessages(library(psych))
knitr::opts_chunk$set(echo = TRUE)

# Checks if package is installed, installs if necessary, and loads package for current session

pacman::p_load(
  lubridate,  # general package for handling and converting dates  
  parsedate,   # has function to "guess" messy dates
  aweek,      # another option for converting dates to weeks, and weeks to dates
  zoo,        # additional date/time functions
  tidyverse,  # data management and visualization  
  rio)        # data import/export
```

# Acknowledgements

NO ACKNOWLEDGEMENTS

# Bradley-Terry Ratings

```{r}

#df_final = read.csv("NBA_2022_23_3pdata_final.csv")
bBall = read.csv("basketball-2022.csv") #%>% filter(Date > )
dim(bBall)

bBall <- bBall %>% 
  mutate(date_adj = as.Date(Date, format = "%a %b %d %Y"))
bBall = bBall %>% filter(date_adj > "2022-02-09")

View(bBall)
dim(bBall)

# this part is a bit complicated, but my best suggestion is to make a new matrix full of zeroes to fill in

teams = sort(unique(bBall$Visitor.Neutral))
num_teams = length(teams)

# we create our data matrix, with columns for each team, the home field intercept and the pt difference
bt_mat = matrix(0, nrow(bBall), num_teams + 2)
# fill in the list of column names for your data matrix
colnames(bt_mat) = c('HFA', 'Pt_Diff', teams)

# then write a for loop to, for each game in your original data, fill in the point diff, home field, and each team's column appropriately

# for each game, add the home and away team
for (i in 1:nrow(bBall)) {
#for (i in 1:5) {
  # we want 1 for the home team, -1 for the away, so we'll use the Away column which tells us if the winner was Away or not
  bt_mat[i,bBall$Home.Neutral[i]] = 1
  bt_mat[i,bBall$Visitor.Neutral[i]] = -1
  
}

# we define 1 for home and -1 for away so the HFA is always the same
bt_mat[,'HFA'] = 1

# we should multiply the point diff by -1 if the winning team was away
bt_mat[,'Pt_Diff'] = (bBall$PTS - bBall$PTS.1) *-1 # equivelant??? 

# if you want to do the unregularized models, create a dataframe

head(bt_mat)
View(bt_mat)
```

## 2.2

Out of four possible versions of Bradley-Terry, some combination of Normal vs Binomial and no regularization vs regularization, fit two of these in R to your data. If your data is only outcomes, then fit the two versions of Binomial Bradley-Terry. If your data includes point differential then you could either use Normal or Binomial Bradley-Terry. \textit{Hint:} To fit the standard model with lm() or glm(), you need the data in a dataframe. But to fit regularization you need the data as a matrix. [\textbf{8 points}]

```{r}

# TIPS FOR NORMAL/BINOMIAL BRADLEY-TERRY
# in both, make sure to exclude the intercept term, and pick the correct response (point diff vs game outcome)

# for NORMAL, use the lm function with your dataframe dat
# MAKE SURE TO EXCLUDE ONE TEAM'S COLUMN, TO SET AS A 0 BETA VALUE

bt_df = data.frame(bt_mat)
#names(bt_df)

# 1) Normal, No regularisation
bt_normal = lm(Pt_Diff ~ . - Washington.Wizards - 1, data = bt_df)
summary(bt_normal)

# for BINOMIAL, use the glm function, with the family = binomial() argument
# otherwise the syntax is the same. MAKE SURE TO STILL EXCLUDE ONE COLUMN

# 2) Binomial, No regularisation
bt_bin = glm(Pt_Diff > 0 ~ . - Washington.Wizards - 1, data = bt_df, family = binomial())
summary(bt_bin)
```

Applying regularization is more challenging, but I'd encourage you to try it out if you'd like. The problem is designed so it is optional, you can always just do the unregularized Normal and Binomial models. See the R file on Canvas for an example of implementing regularization.

```{r}

# TIPS FOR BRADLEY-TERRY WITH REGULARIZATION

# regularization is done with the glmnet library and function
# you need to make a matrix X and response vector y
# then you can use cv.glmnet(), with a vector of lambdas
# use argument alpha = 0, which indicates ridge regularization


# after fitting the cv.glmnet(), you can use the 'best' lambda with the predict function, with the name of your fit, the X vector, and argument s = 'lambda_min'

```

## 2.3

Compare the results of each model in at least two different ways. Some examples include comparing the predictions on your training dataset, comparing the ranking of teams and relative sizes of their coefficients, comparing accuracy of predicting test data (such as the bowl games in the NCAA football data), etc. [\textbf{4 points}]

```{r}

# I won't give scaffolding for this, but here are some tips
# but consider using model$coefficients on your model object to see coefficients
# the sort function might be helpful, with argument decreasing = TRUE
# First comparison, examining which teams agrees and which are disputed
names(sort(bt_normal$coefficients[-1], decreasing=TRUE))
print("-----")
sort(bt_bin$coefficients[-1], decreasing=TRUE)

rankingNormal   = sort(bt_normal$coefficients[-1], decreasing=TRUE)[1:5] # -1 to remove HFA
rankingBinomial = sort(bt_bin$coefficients[-1], decreasing=TRUE)[1:5]    # -1 to remove HFA
#print(rankingNormal)
rankingNormalNames   = names(rankingNormal)
rankingBinomialNames = names(rankingBinomial)

teamsAgreed = list()
teamsNotAgreed = list()
for (item in rankingNormalNames) {
  if (item %in% rankingBinomialNames) {
    #print(item)
    #teamsAgreed.append(item)
    teamsAgreed <- c(teamsAgreed, item)
  } else {
    teamsNotAgreed <- c(teamsNotAgreed, item)
  }
}

print("Teams agreed upon in top 5: ")
for (item in teamsAgreed) {
  print(item)
}
print("--------")
print("Teams disagreed upon in top 5: ")
for (item in teamsNotAgreed) {
  print(item)
}
```

```{r}

# you can predict with the predict() function, and with those predictions determine which team the model thinks will win a game
bowlGames = read.csv("power5fbs.csv") %>% filter(Wk >= 17)
#View(bowlGames)

# we create our data matrix, with columns for each team, the home field intercept and the pt difference
bt_bowl_mat = matrix(0, nrow(bowlGames), num_teams + 2)
# fill in the list of column names for your data matrix
colnames(bt_bowl_mat) = c('HFA', 'Pt_Diff', teams)

# then write a for loop to, for each game in your original data, fill in the point diff, home field, and each team's column appropriately
# for each game, add the home and away team
for (i in 1:nrow(bowlGames)) {
  # we want 1 for the home team, -1 for the away, so we'll use the Away column which tells us if the winner was Away or not
  bt_bowl_mat[i,bowlGames$Winner[i]] = 2 * (bowlGames$Site[i] != '@') - 1
  bt_bowl_mat[i,bowlGames$Loser[i]]  = 2 * (bowlGames$Site[i] == '@') - 1
}

# we define 1 for home and -1 for away so the HFA is always the same
bt_bowl_mat[,'HFA'] = 1
# we should multiply the point diff by -1 if the winning team was away
bt_bowl_mat[,'Pt_Diff'] = (bowlGames$Pts - bowlGames$Pts.1) * (2 * (bowlGames$Site != '@') - 1)

# in order to predict on test data, you will have to create either a new dataframe or matrix with the same number of columns/labeling format

bt_bowl_df = data.frame(bt_bowl_mat)
bt_normal_pred   = predict(bt_normal, bt_bowl_df)
bt_binomial_pred = predict(bt_bin, bt_bowl_df)

# For this bowl games all were won by the first team so this will work
bt_normal_pred_accuracy   = bt_normal_pred > 0
bt_binomial_pred_accuracy = bt_binomial_pred > 0

bt_normal_correct   = sum(bt_normal_pred_accuracy)
bt_binomial_correct = sum(bt_binomial_pred_accuracy)

print(bt_normal_correct / nrow(bt_bowl_df))
print(bt_binomial_correct / nrow(bt_bowl_df))

```

The models agrees that both Georgia and Tennessee are in the top 5 teams but disagree on Kansas State, Texas Christian, and Texas.

The normal model outperformed the normal model on predicting the bowl results in the games (80.95238% vs 52.38095%)

## 2.4

In either model you fit, what are some model assumptions that you find problematic that might lead to shortcomings in the results? [\textbf{2 points}]

Shortcomings: styles of play affecting which teams beat which, injuries affecting performance, small number of games in training set, trading of players mid season.
