---
title: "Stats 100: Project"
author: "Niall Kehoe"
date: "05/11/2023"
header-includes:
   - \usepackage{bbm, amsmath,amsfonts,amsthm,amssymb,mathrsfs,amsxtra,amscd,latexsym, xcolor, graphicx, fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
output: pdf_document
---

\newcommand{\Var}{\mathrm{Var}}

```{r}
#in order to run this code, you will need to install these packages. You can do so by going to the install button, or by going to the console and typing, for example, install.packages("knitr")
suppressPackageStartupMessages(library(knitr)) #makes pdfs
suppressPackageStartupMessages(library(latex2exp))
suppressPackageStartupMessages(library(ggplot2)) #makes nice plots
suppressPackageStartupMessages(library(tidyverse))
#good library for data manipulation, includes dplyr and ggplot
# you can read more about the tidyverse at: https://r4ds.had.co.nz/
# you'll need this library for regularization if you use it

#install.packages('glmnet', dependencies=TRUE, type="binary")
#install.packages('predtools', dependencies=TRUE, type="binary")
#install.packages('psych', dependencies=TRUE, type="binary")

suppressPackageStartupMessages(library(glmnet))
suppressPackageStartupMessages(library(predtools))
suppressPackageStartupMessages(library(psych))
knitr::opts_chunk$set(echo = TRUE)

# Checks if package is installed, installs if necessary, and loads package for current session

pacman::p_load(
  lubridate,  # general package for handling and converting dates  
  parsedate,   # has function to "guess" messy dates
  aweek,      # another option for converting dates to weeks, and weeks to dates
  zoo,        # additional date/time functions
  tidyverse,  # data management and visualization  
  rio)        # data import/export
```

# Acknowledgements

NO ACKNOWLEDGEMENTS

# Bradley-Terry Ratings

```{r}

#df_final = read.csv("NBA_2022_23_3pdata_final.csv")
bBall = read.csv("NBA/basketball-2021.csv") #%>% filter(Date > )
dim(bBall)

bBall <- bBall %>% 
  mutate(date_adj = as.Date(Date, format = "%a %b %d %Y"))
FILTER_DATE_CUTOFF = "2022-02-09"

#List of hospitals we want to do further analysis on
# goodHosp <- c("Atlanta Hawks", "Boston Celtics", "Brooklyn Nets", "Charlotte Hornets", "Chicago Bulls", "Cleveland Cavaliers", "Detroit Pistons", "Indiana Pacers", "Miami Heat", "Milwaukee Bucks", "New York Knicks", "Orlando Magic", "Philadelphia 76ers", "Toronto Raptors", "Washington Wizards")

bBall = bBall %>% filter(date_adj > FILTER_DATE_CUTOFF) 
# %>% filter(Visitor.Neutral  %in% goodHosp) %>% filter(Home.Neutral  %in% goodHosp)
# new conference filter
  
View(bBall)
dim(bBall)




#TRY RESTRICTING TO JUST WESTERN / EASTERN CONFERENCES


# this part is a bit complicated, but my best suggestion is to make a new matrix full of zeroes to fill in

teams = sort(unique(bBall$Home.Neutral))
num_teams = length(teams)

# we create our data matrix, with columns for each team, the home field intercept and the pt difference
bt_mat = matrix(0, nrow(bBall), num_teams + 2)
# fill in the list of column names for your data matrix
colnames(bt_mat) = c('HFA', 'Pt_Diff', teams)

# then write a for loop to, for each game in your original data, fill in the point diff, home field, and each team's column appropriately

# for each game, add the home and away team
for (i in 1:nrow(bBall)) {
#for (i in 1:5) {
  # we want 1 for the home team, -1 for the away, so we'll use the Away column which tells us if the winner was Away or not
  bt_mat[i,bBall$Home.Neutral[i]] = 1
  bt_mat[i,bBall$Visitor.Neutral[i]] = -1
  
}

# we define 1 for home and -1 for away so the HFA is always the same
bt_mat[,'HFA'] = 1

# we should multiply the point diff by -1 if the winning team was away
bt_mat[,'Pt_Diff'] = (bBall$PTS - bBall$PTS.1) *-1 # equivelant??? 

# if you want to do the unregularized models, create a dataframe

head(bt_mat)
View(bt_mat)
```

## 2.2

Out of four possible versions of Bradley-Terry, some combination of Normal vs Binomial and no regularization vs regularization, fit two of these in R to your data. If your data is only outcomes, then fit the two versions of Binomial Bradley-Terry. If your data includes point differential then you could either use Normal or Binomial Bradley-Terry. \textit{Hint:} To fit the standard model with lm() or glm(), you need the data in a dataframe. But to fit regularization you need the data as a matrix. [\textbf{8 points}]

```{r}

# TIPS FOR NORMAL/BINOMIAL BRADLEY-TERRY
# in both, make sure to exclude the intercept term, and pick the correct response (point diff vs game outcome)

# for NORMAL, use the lm function with your dataframe dat
# MAKE SURE TO EXCLUDE ONE TEAM'S COLUMN, TO SET AS A 0 BETA VALUE

bt_df = data.frame(bt_mat)
#names(bt_df)

# 1) Normal, No regularisation
bt_normal = lm(Pt_Diff ~ . - Washington.Wizards - 1, data = bt_df)
summary(bt_normal)

# for BINOMIAL, use the glm function, with the family = binomial() argument
# otherwise the syntax is the same. MAKE SURE TO STILL EXCLUDE ONE COLUMN

# 2) Binomial, No regularisation
bt_bin = glm(Pt_Diff > 0 ~ . - Washington.Wizards - 1, data = bt_df, family = binomial())
summary(bt_bin)
```

Applying regularization is more challenging, but I'd encourage you to try it out if you'd like. The problem is designed so it is optional, you can always just do the unregularized Normal and Binomial models. See the R file on Canvas for an example of implementing regularization.

```{r}

# TIPS FOR BRADLEY-TERRY WITH REGULARIZATION

# regularization is done with the glmnet library and function
# you need to make a matrix X and response vector y
# then you can use cv.glmnet(), with a vector of lambdas
# use argument alpha = 0, which indicates ridge regularization


# after fitting the cv.glmnet(), you can use the 'best' lambda with the predict function, with the name of your fit, the X vector, and argument s = 'lambda_min'

```

## 2.3

Compare the results of each model in at least two different ways. Some examples include comparing the predictions on your training dataset, comparing the ranking of teams and relative sizes of their coefficients, comparing accuracy of predicting test data (such as the bowl games in the NCAA football data), etc. [\textbf{4 points}]

```{r}

# I won't give scaffolding for this, but here are some tips
# but consider using model$coefficients on your model object to see coefficients
# the sort function might be helpful, with argument decreasing = TRUE
# First comparison, examining which teams agrees and which are disputed
names(sort(bt_normal$coefficients[-1], decreasing=TRUE))
print("-----")
sort(bt_bin$coefficients[-1], decreasing=TRUE)

# rankingNormal   = sort(bt_normal$coefficients[-1], decreasing=TRUE)[1:5] # -1 to remove HFA
# rankingBinomial = sort(bt_bin$coefficients[-1], decreasing=TRUE)[1:5]    # -1 to remove HFA
# #print(rankingNormal)
# rankingNormalNames   = names(rankingNormal)
# rankingBinomialNames = names(rankingBinomial)
# 
# teamsAgreed = list()
# teamsNotAgreed = list()
# for (item in rankingNormalNames) {
#   if (item %in% rankingBinomialNames) {
#     #print(item)
#     #teamsAgreed.append(item)
#     teamsAgreed <- c(teamsAgreed, item)
#   } else {
#     teamsNotAgreed <- c(teamsNotAgreed, item)
#   }
# }
# 
# print("Teams agreed upon in top 5: ")
# for (item in teamsAgreed) {
#   print(item)
# }
# print("--------")
# print("Teams disagreed upon in top 5: ")
# for (item in teamsNotAgreed) {
#   print(item)
# }
```

```{r}

#length(names(sort(bt_normal$coefficients[-1], decreasing=TRUE)))
teamNames = names(sort(bt_normal$coefficients[-1], decreasing=TRUE))
append(teamNames, "Washington.Wizards")
# DONT FORGET TO ADD BACK IN BASELINE at 0

NBASalaries = read.csv("NBA/basketball-2021-salary.csv")#  %>% filter(Team %in% goodHosp)
#View(NBASalaries)

NBASalaries
#NBASalaryDict = {}

#for(i in 1:nrow(NBASalaries)) {
#  formattedName = NBASalaries[i,]$Team
#  formattedName <- str_replace_all(formattedName, " ", ".")
#  NBASalaryDict[formattedName] = substring(NBASalaries[i,]$X2022.23,2)
#}

#NBASalaryDict
```

```{r}

coeffs = bt_normal$coefficients[-1]
coeffs["Washington.Wizards"] = 0

NBASalaries <- NBASalaries[order(NBASalaries$Team,decreasing=FALSE),]

dfResult <- data.frame(coeffs, NBASalaries$X2021.22, NBASalaries$Rk)# %>% mutate(Salaries = NBASalaries$X2022.23 %>% str_remove_all("\\$,") %>% as.numeric())
dfResult$Salaries = as.numeric(gsub("\\$", "", dfResult$NBASalaries.X2021.22))
dfResult$Salaries = dfResult$Salaries / 1000000

View(dfResult)

# Plot the chart for cars with weight between 2.5 to 5 and mileage between 15 and 30.
plot(x = dfResult$Salaries, y = dfResult$coeffs,
   xlab = "Salaries (millions)",
   ylab = "Performance (Pt diff vs Washington Wizards)",	 
   main = "A: Salaries vs Performance"
)
abline(lm(dfResult$coeffs ~ dfResult$Salaries), col='blue')

modelCoeff = lm(coeffs ~ Salaries, data = dfResult)
summary(modelCoeff)




# Divide by average salary -try 
```

```{r}

hist(dfResult$Salaries, col = 'skyblue3', breaks = 15, 
   xlab = "Salaries (millions)",
   main = "Salaries vs Frequency")
```

```{r}

dfResult <- dfResult[order(dfResult$coeffs,decreasing=FALSE),]
ranksMap = seq(1, 30, by=1)
dfResult$coeffRank = ranksMap
dfResult
```

```{r}


# Plot the chart for cars with weight between 2.5 to 5 and mileage between 15 and 30.
plot(x = dfResult$Salaries, y = dfResult$coeffRank,
   xlab = "Salaries (millions)",
   ylab = "Performance by ranking in BT",	 
   main = "Salaries vs Performance"
)

cor(dfResult$Salaries, dfResult$coeffRank)

modelRank = lm(coeffRank ~ Salaries, data = dfResult)
summary(modelRank)

# Log change

plot(x = log(dfResult$Salaries), y = dfResult$coeffRank,
   xlab = "Salaries (millions)",
   ylab = "Performance by ranking in BT",	 
   main = "log(Salaries) vs Performance"
)
modelRank = lm(coeffRank ~ log(Salaries), data = dfResult)
summary(modelRank)
```

```{r}

# NBA RANKINGS W-L

standings = read.csv("NBA/basketball-2021-standings.csv") #%>% filter(Date > )
dfStandings <- data.frame(standings$Team, ranksMap) #NBASalaries$X2021.22, NBASalaries$Rk)

NBASalaries <- NBASalaries[order(NBASalaries$Team,decreasing=FALSE),]
dfStandings <- dfStandings[order(dfStandings$standings.Team,decreasing=FALSE),]

dfStandings$Salaries = NBASalaries$X2021.22
dfStandings$Salaries = as.numeric(gsub("\\$", "", dfStandings$Salaries))
dfStandings$Salaries = dfStandings$Salaries / 1000000

#dfStandings <- dfStandings[order(dfStandings$dfStandings.Team,decreasing=FALSE),]


colnames(dfStandings) <- c("Team", "ranking", "Salaries")


dfStandings$rankingA = 30- dfStandings$ranking

View(dfStandings)

plot(x = dfStandings$Salaries, y = dfStandings$ranking,
   xlab = "Salaries (millions)",
   ylab = "Performance by ranking No. wins (lower better)",	 
   main = "Salaries vs Performance"
)

plot(x = dfStandings$Salaries, y = dfStandings$rankingA,
   xlab = "Salaries (millions)",
   ylab = "Inverted Ranking (higher better)",	 
   main = "B: Salaries vs Performance"
)
abline(lm(dfStandings$rankingA ~ dfStandings$Salaries), col='blue')


modelRank = lm(rankingA ~ Salaries, data = dfStandings)
summary(modelRank)

# Try
# Total score / $ spent
```

## 2.4

In either model you fit, what are some model assumptions that you find problematic that might lead to shortcomings in the results? [\textbf{2 points}]

Shortcomings: styles of play affecting which teams beat which, injuries affecting performance, small number of games in training set, trading of players mid season.
